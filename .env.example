# ========================
# BlueCom Network Troubleshooter - Environment Variables Template
# ========================
# 
# INSTRUCTIONS:
# 1. Copy this file and rename it to: .env
# 2. Fill in your actual values (NEVER commit .env to Git!)
# 3. Keep .env in your local machine only
#
# ⚠️ SECURITY WARNING:
# - Never commit .env file to version control
# - Never share these credentials
# - Add .env to .gitignore
# ========================

# ========================
# Qdrant Vector Database Configuration
# ========================
# Get your Qdrant credentials from: https://cloud.qdrant.io/
QDRANT_URL=https://xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx.us-east-1-0.aws.cloud.qdrant.io:6333
QDRANT_API_KEY=your_qdrant_api_key_here
QDRANT_COLLECTION=network_issues

# ========================
# AWS Configuration
# ========================
# Get your AWS credentials from: AWS IAM Console
# Never use root account credentials - create IAM user with limited permissions
AWS_ACCESS_KEY_ID=AKIAXXXXXXXXXXXXXXXXX
AWS_SECRET_ACCESS_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
AWS_REGION=us-east-1
S3_BUCKET_NAME=your-bucket-name

# ========================
# Optional: Hugging Face (if using private models)
# ========================
# Get token from: https://huggingface.co/settings/tokens
# HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# ========================
# Optional: OpenAI (if integrating GPT models)
# ========================
# Get API key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# ========================
# Optional: Anthropic Claude (if using Claude API)
# ========================
# Get API key from: https://console.anthropic.com/
# ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# ========================
# Application Configuration
# ========================
# Environment (development, staging, production)
ENVIRONMENT=development

# Debug mode (true/false)
DEBUG=false

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# ========================
# Model Configuration (Optional)
# ========================
# Embedding model name
# EMBEDDING_MODEL=all-MiniLM-L6-v2

# LLM model name
# LLM_MODEL=google/gemma-2b-it

# Max tokens for LLM generation
# MAX_TOKENS=220

# Temperature for LLM (0.0 to 1.0)
# TEMPERATURE=0.8

# ========================
# EXAMPLE VALUES (for reference)
# ========================
# Below are examples showing the format. Replace with your actual values!
#
# QDRANT_URL=https://abc12345-1234-5678-9abc-def123456789.us-east-1-0.aws.cloud.qdrant.io:6333
# QDRANT_API_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...
# AWS_ACCESS_KEY_ID=AKIAIOSFODNN7EXAMPLE
# AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
# S3_BUCKET_NAME=my-company-network-data
#
# ========================
# IMPORTANT NOTES:
# ========================
# 1. Qdrant URL format: https://[cluster-id].[region].aws.cloud.qdrant.io:6333
# 2. AWS credentials should be for an IAM user, not root account
# 3. S3 bucket must exist and IAM user must have write permissions
# 4. Never commit this file with real values to Git
# 5. Rotate credentials if accidentally exposed
# ========================
